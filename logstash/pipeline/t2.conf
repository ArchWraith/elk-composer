input {
    file {
        path => "/usr/share/logstash/pipeline/SampleData.csv"
        start_position => beginning
    }
}

filter {
    csv {
        columns => [
            "Id",
            "Name",
            "Birthday",
            "Gifted",
            "Power",
            "lat",
            "lon"
        ]
        
        separator => ","
    }
    mutate {
        add_field => {"Loc" => "%{lat},%{lon}"}
        convert => {
            "Id" => "integer"
            "Name" => "string"
            "Birthday" => "string"
            "Gifted" => "boolean"
            "Power" => "float"
            "Loc" => "string"
        }
    }
}

output {
    elasticsearch {
        hosts => ["elasticsearch:9200"]
        user => "elastic"
        password => "changeme"
        action => "index"
        index => "test_data2"
    }
    stdout {
        codec => rubydebug
    }
}